{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Angle Between Three Point (1.shoulder,2.elbow,3.wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(SHOULDER,ELBOW,WRIST):\n",
    "    \"\"\"\n",
    "    _ calculate_angle:Function to calculate angle between three point (1.shoulder,2.elbow,3.wrist)\n",
    "    _ shoulder:pose landmark number 11 and 12 containe X_position and Y_position\n",
    "    _ elbow:pose landmark number 13 and 14 containe X_position and Y_position\n",
    "    _ wrist:pose landmark number 15 and 16 containe X_position and Y_position\n",
    "    \"\"\"\n",
    "    SHOULDER = np.array(SHOULDER) # First\n",
    "    ELBOW = np.array(ELBOW) # Mid\n",
    "    WRIST = np.array(WRIST) # End\n",
    "    \n",
    "    radians = np.arctan2(WRIST[1]-ELBOW[1],WRIST[0]-ELBOW[0])-np.arctan2(SHOULDER[1]-ELBOW[1],SHOULDER[0]-ELBOW[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180:\n",
    "        angle = 360-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Distances Between Point in Curent Frame and Point in Previose Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(delta_t,landmark_1,landmark_2):\n",
    "    \"\"\"\n",
    "    _ calculate_distances:Function to calculate distances for specific landmark (shoulder,elbow,wrist,hip,knee,ankle \"_left&right_\")\n",
    "    between point in curent frame and point in previose frame\n",
    "    _ index:number of curent frame\n",
    "    _ fps:number of frame per seconde\n",
    "    _ landmark_1:pose landmark for curent frame\n",
    "    _ landmark_2:pose landmark for previose frame\n",
    "    \"\"\"\n",
    "    my_list = []\n",
    "    for ind in range(len(landmark_1)):\n",
    "        if ((ind>0)and(ind<=10))or((ind>=17)and(ind<=32)):\n",
    "            continue\n",
    "        p1 = [landmark_1[ind].x,landmark_1[ind].y]\n",
    "        p2 = [landmark_2[ind].x,landmark_2[ind].y]\n",
    "        my_list.append(np.array([[p1[0]],[p1[1]]])) # ,[(p1[0]-p2[0])/delta_t],[(p1[1]-p2[1])/delta_t]\n",
    "    return my_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Filter Equation Prediction Update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction_update(X,A,P,Q):\n",
    "    \"\"\"\n",
    "    _ Prediction_update:Function to Applying Prediction Equation\n",
    "    _ X:State Matrix [X_position,Y_position,X_velocity,Y_velocity]\n",
    "    _ A:State Transition\n",
    "    _ P:Process Covariance Matrix\n",
    "    _ Q:Erorr Terms\n",
    "    \"\"\"\n",
    "    X = A.dot(X)\n",
    "    TEPM = A.dot(P)\n",
    "    P = TEPM.dot(A.T)+Q\n",
    "    return X,P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kalman Filter Equation Measurement Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Measurement_update(Z,X,P,H,R):\n",
    "    \"\"\"\n",
    "    _ Measurement_update:Function to Applying Measurement Equation\n",
    "    _ X:State Matrix [X_position,Y_position,X_velocity,Y_velocity]\n",
    "    _ P:Process Covariance Matrix\n",
    "    _ H:unit matrix\n",
    "    _ R:Erorr Terms of the Measurement\n",
    "    \"\"\"\n",
    "    I = np.array([[1,0],\n",
    "                  [0, 1]])\n",
    "    \n",
    "    T1 = P.dot(H.T)\n",
    "    T2 = H.dot(P)\n",
    "    T3 = T2.dot(H.T)\n",
    "    T3 = T3 + R\n",
    "    K = T1.dot(np.linalg.inv(T3))\n",
    "    \n",
    "    T1 = H.dot(X)\n",
    "    T2 = Z - T1\n",
    "    T3 = K.dot(T2)\n",
    "    X = X + T3\n",
    "    \n",
    "    T1 = K.dot(H)\n",
    "    T2 = I - T1\n",
    "    P = T2.dot(P)\n",
    "\n",
    "    return X,P,K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get all video in any root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(path_folder):\n",
    "    \"\"\"\n",
    "    _ get_videos:Function to get all videos in root path\n",
    "    _ input:(path_folder) the root path for all dirctory that contant video\n",
    "    _ output:(folders) all dirctory in root path (all_video_paths) all paths video\n",
    "    \"\"\"\n",
    "    folders = os.listdir(path_folder)\n",
    "    all_video_paths = []\n",
    "    for folder in folders:\n",
    "        curr_dataset_path = os.path.join(path_folder, folder)\n",
    "        try:\n",
    "            videos = os.listdir(curr_dataset_path)\n",
    "        except:\n",
    "            if \".mp4\" in curr_dataset_path:\n",
    "                all_video_paths.append(curr_dataset_path)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "        for video_p in videos:\n",
    "            all_video_paths.append(os.path.join(curr_dataset_path, video_p))\n",
    "    return folders , all_video_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Average for List or Array of Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    \"\"\"\n",
    "    _Average:Function to calculate mean for list or array\n",
    "    _input:List or array of numbers\n",
    "    _output:the mean for input numbre\n",
    "    \"\"\"\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save any Object We Need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    \"\"\"\n",
    "    _save_object:Function to save any object\n",
    "    _input:(obj) the object that we want save , (filename) Memorization path \n",
    "    \"\"\"\n",
    "    with open(filename+\".pkl\", 'wb') as outp:\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    outp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save any Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(filename):\n",
    "    \"\"\"\n",
    "    _load_object:Function to load any object\n",
    "    _input:object path \n",
    "    _output:the object\n",
    "    \"\"\"\n",
    "    with open(filename+\".pkl\", 'rb') as outp:\n",
    "        loaded_object = pickle.load(outp)\n",
    "    outp.close()\n",
    "    return loaded_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate angles between shoulder and elbow and wrist point for left and right hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_left_right_arm_angle(landmarks,mp_pose,X=None):\n",
    "    \"\"\"\n",
    "    _ calculate_left_right_arm_angle:Function to calculate angle between three points from arm \n",
    "    _ input: (landmarks) all pose points , (mp_pose) contante all landmark name\n",
    "    _ output: left and right angle for tow arm\n",
    "    \"\"\"\n",
    "    if X!=None:\n",
    "        LEFTangle = calculate_angle([X[1][0][0],X[1][1][0]],[X[3][0][0],X[3][1][0]],[X[5][0][0],X[5][1][0]])\n",
    "        RIGHTangle = calculate_angle([X[2][0][0],X[2][1][0]],[X[4][0][0],X[4][1][0]],[X[6][0][0],X[6][1][0]])\n",
    "        return LEFTangle,RIGHTangle\n",
    "    # Get coordinates for left points\n",
    "    LEFTshoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    LEFTelbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    LEFTwrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "    # calculate LEFT angle\n",
    "    LEFTangle = calculate_angle(LEFTshoulder,LEFTelbow,LEFTwrist)\n",
    "\n",
    "    # Get coordinates for right points\n",
    "    RIGHTshoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    RIGHTelbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    RIGHTwrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "    # calculate RIGHT angle\n",
    "    RIGHTangle = calculate_angle(RIGHTshoulder,RIGHTelbow,RIGHTwrist)\n",
    "    return LEFTangle,RIGHTangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if ram is moving or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hand_moving(pre_angle,cur_angle):\n",
    "    \"\"\"\n",
    "    _ check_hand_moving: Function to check if arm moving or not \n",
    "    _ input: (pre_angle) angle from previose frame (cur_angle) angle from curent frame\n",
    "    _ output: (True) if arm moving (False) if arm not moving \n",
    "    \"\"\"\n",
    "    angle = cur_angle-pre_angle\n",
    "    stage=False\n",
    "    if angle>5:\n",
    "        stage = True\n",
    "    return stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### give the results of the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_get_decistion(l_is_moved,r_is_moved):\n",
    "    \"\"\"\n",
    "    _ hand_get_decistion: get decis\n",
    "    _ input: (\"l_is_moved\") true if left arm is moved or false if not , (\"r_is_moved\") true if right arm is moved or false if not\n",
    "    _ output: (Moving Hand , 1) or (Rest Hand 0)\n",
    "    \"\"\"\n",
    "    if l_is_moved or r_is_moved:\n",
    "        return \"Moving Hand\",1\n",
    "    return \"Rest Hand\",0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Drawing_utils(image,results,mp_pose):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(245,117,66),thickness=4,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(245,66,230),thickness=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_kalman_parameters(delta_t):\n",
    "    A = np.array([[1, delta_t],[0, 1]]) # STATE MATRIC (The relationship between system variables in the equations of motion)\n",
    "    P = np.eye(2)*10 # Guess Kalmen , Uncertainty Matrix , The relationship of state variables , external forces\n",
    "    H = np.eye(2) # Measurement matrix is used to calculate Calmen error\n",
    "    R = np.eye(2)*0.05 # Noise added for update\n",
    "    Q =np.eye(2)*0.1 # Noise added for measurement\n",
    "    X = []\n",
    "    for i in range(7):\n",
    "        X.append(np.array([[0],[0]]))\n",
    "    return A,P,H,R,Q,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(p1,p2):\n",
    "    return math.sqrt((p2[0]-p1[0])**2+(p2[1]-p1[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_body_moving(i,head_points,elbo_points):\n",
    "    if ((head_points[-1]>=elbo_points[-2][1]) and (head_points[-1]<=elbo_points[-2][0])) :# or ((head_points[-1]>elbo_points[-3][1]) and (head_points[-1]<elbo_points[-3][0])) or ((head_points[-1]>elbo_points[-4][1]) and (head_points[-1]<elbo_points[-4][0])):\n",
    "        return False\n",
    "    if ((elbo_points[-2][0]-elbo_points[-2][1])>(elbo_points[-1][0]-elbo_points[-1][1])):\n",
    "        return True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the video, perform the required calculations, and then save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(path_A):\n",
    "    freeRIGHT = []\n",
    "    freeLEFT = []\n",
    "    ind = []\n",
    "    temp = True\n",
    "    head_points = []\n",
    "    elbo_points = []\n",
    "    decistion_hand = \"\"\n",
    "    decistion_body = \"\"\n",
    "    path_A_ = path_A.split(\"\\\\\")\n",
    "    key = path_A_[-1].split(\".\")[-2].split(\"-\")[-1]+\" \"+path_A_[-2].split(\"-\")[-1]\n",
    "    print(key)\n",
    "    HFrameLable[key] = []\n",
    "    MFrameLable[key] = []\n",
    "    points_in_frames = []\n",
    "    my_list = []\n",
    "    index = 0 \n",
    "    mp_pose = mp.solutions.pose \n",
    "    cap = cv2.VideoCapture(path_A)\n",
    "    # We need to check if camera\n",
    "    # is opened previously or not\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Error reading video file\")\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    size = (frame_width, frame_height)\n",
    "    # count the number of frames\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # calculate duration of the video\n",
    "    seconds = round(frames / fps)\n",
    "    video_time = datetime.timedelta(seconds=seconds)\n",
    "    delta_t = 1/fps\n",
    "    A,P,H,R,Q,X = creat_kalman_parameters(delta_t)\n",
    "    # Pose : is the algorithem that will be do detection for 33 pointes\n",
    "    ## setup mediapipe instance\n",
    "    te = 0 \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if (not ret) or (cv2.waitKey(10)==ord('q')):\n",
    "                break\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "            # Recolor to BGR\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "            # Extract lnadmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                points_in_frames.append(landmarks)\n",
    "                \n",
    "                if index!=0 and (index%fps==0):\n",
    "                    my_list = calculate_distances(delta_t,points_in_frames[index],points_in_frames[index-1])\n",
    "                    if index==15:\n",
    "                        X = my_list\n",
    "                    for i in range(len(my_list)):\n",
    "                        Z = my_list[i]\n",
    "                        X[i] , P = Prediction_update(X[i],A,P,Q)\n",
    "                        X[i] , P , K = Measurement_update(Z,X[i],P,H,R)\n",
    "\n",
    "\n",
    "                NOSE = landmarks[mp_pose.PoseLandmark.NOSE.value].x\n",
    "                LEFT_SHOULDER = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x\n",
    "                RIGHT_SHOULDER = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x\n",
    "                \n",
    "                if NOSE and te<2:\n",
    "                    head_points.append(NOSE)\n",
    "                    elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "                    te+=1\n",
    "                if len(head_points)>=1:\n",
    "                    head_points.append(NOSE)\n",
    "                    if check_body_moving(index,head_points,elbo_points):\n",
    "                        elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "                        decistion_body,Ndecistion_body = \"Moving Body\",1   \n",
    "                    else:\n",
    "                        decistion_body,Ndecistion_body = \"Rest Body\",0\n",
    "                \n",
    "                LEFTangle , RIGHTangle = calculate_left_right_arm_angle(landmarks,mp_pose)\n",
    "                freeLEFT.append(LEFTangle)\n",
    "                freeRIGHT.append(RIGHTangle)\n",
    "                if len(freeLEFT)>1:\n",
    "                    l_is_moved = check_hand_moving(freeLEFT[-2],freeLEFT[-1])\n",
    "                else:\n",
    "                    l_is_moved = False\n",
    "                if len(freeRIGHT)>1:\n",
    "                    r_is_moved =check_hand_moving(freeRIGHT[-2],freeRIGHT[-1])\n",
    "                else:\n",
    "                    r_is_moved = False\n",
    "                decistion_hand,Ndecistion_hand = hand_get_decistion(l_is_moved,r_is_moved)\n",
    "                HFrameLable[key].append(Ndecistion_hand)\n",
    "                MFrameLable[key].append(Ndecistion_body)\n",
    "                ind.append(index)\n",
    "                index+=1\n",
    "            except:\n",
    "                pass\n",
    "            cv2.putText(image,decistion_hand,(0,25),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "            cv2.putText(image,decistion_body,(0,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "#             Drawing_utils(image,results,mp_pose)\n",
    "            \n",
    "            cv2.imshow('Body Movement Taske',image)\n",
    "            if cv2.waitKey(10)==ord('q'):\n",
    "                break\n",
    "    indall.append(ind)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_folder = 'D:\\\\DataSet\\\\representatiion_scoring_data_set'\n",
    "# folders ,videos = get_videos(path_folder)\n",
    "# HFrameLable = {}\n",
    "# MFrameLable = {}\n",
    "# FrameLable = {}\n",
    "# indall = []\n",
    "# folders , all_video_paths = get_videos(path_folder)\n",
    "# for i in [all_video_paths[0],all_video_paths[14]]:\n",
    "#     try:\n",
    "#         pipeline(i)\n",
    "#     except:\n",
    "#         pass\n",
    "# for i in HFrameLable:\n",
    "#     FrameLable[i] = [HFrameLable[i],MFrameLable[i]]\n",
    "# # save_object(FrameLable,\"FrameLable++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_object(HFrameLable,\"HFrameLable\")\n",
    "# save_object(MFrameLable,\"MFrameLable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i,j in enumerate(HFrameLable):\n",
    "#     print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in [all_video_paths[0],all_video_paths[14]]:\n",
    "#     cap = cv2.VideoCapture(i)\n",
    "#     # We need to check if camera\n",
    "#     # is opened previously or not\n",
    "#     if (cap.isOpened() == False): \n",
    "#         print(\"Error reading video file\")\n",
    "#     frame_width = int(cap.get(3))\n",
    "#     frame_height = int(cap.get(4))\n",
    "#     size = (frame_width, frame_height)\n",
    "#     # count the number of frames\n",
    "#     frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     # calculate duration of the video\n",
    "#     seconds = round(frames / fps)\n",
    "#     video_time = datetime.timedelta(seconds=seconds)\n",
    "#     print(int(frames)-len(indall[1]),int(frames),len(indall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_with_kalman(path_A):\n",
    "    ind = []\n",
    "    freeRIGHT = []\n",
    "    freeLEFT = []\n",
    "    temp = True\n",
    "    head_points = []\n",
    "    elbo_points = []\n",
    "    decistion_hand = \"\"\n",
    "    decistion_body = \"\"\n",
    "    path_A_ = path_A.split(\"\\\\\")\n",
    "    key = path_A_[-1].split(\".\")[-2].split(\"-\")[-1]+\" \"+path_A_[-2].split(\"-\")[-1]\n",
    "    print(key)\n",
    "    HFrameLable_kalman[key] = []\n",
    "    MFrameLable_kalman[key] = []\n",
    "    \n",
    "    points_in_frames = []\n",
    "    my_list = []\n",
    "    index = 0 \n",
    "    mp_pose = mp.solutions.pose \n",
    "    cap = cv2.VideoCapture(path_A)\n",
    "    # We need to check if camera\n",
    "    # is opened previously or not\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Error reading video file\")\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    size = (frame_width, frame_height)\n",
    "    # count the number of frames\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # calculate duration of the video\n",
    "    seconds = round(frames / fps)\n",
    "    video_time = datetime.timedelta(seconds=seconds)\n",
    "    delta_t = 1/fps\n",
    "    A,P,H,R,Q,X = creat_kalman_parameters(delta_t)\n",
    "    # Pose : is the algorithem that will be do detection for 33 pointes\n",
    "    ## setup mediapipe instance\n",
    "    te = 0 \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if (not ret) or (cv2.waitKey(10)==ord('q')):\n",
    "                break\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "            # Recolor to BGR\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "            # Extract lnadmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                points_in_frames.append(landmarks)\n",
    "#                 if index!=0:\n",
    "                my_list = calculate_distances(delta_t,points_in_frames[index],points_in_frames[index-1])\n",
    "\n",
    "                if index==1:\n",
    "                    X = my_list\n",
    "                for i in range(len(my_list)):\n",
    "                    Z = my_list[i]\n",
    "                    X[i] , P = Prediction_update(X[i],A,P,Q)\n",
    "                    X[i] , P , K = Measurement_update(Z,X[i],P,H,R)\n",
    "                NOSE = X[0][0][0]\n",
    "                LEFT_SHOULDER = X[1][0][0]\n",
    "                RIGHT_SHOULDER = X[2][0][0]\n",
    "                if NOSE and te<2:\n",
    "                    head_points.append(NOSE)\n",
    "                    elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "                    te+=1\n",
    "                if len(head_points)>=1:\n",
    "                    head_points.append(NOSE)\n",
    "                    if check_body_moving(index,head_points,elbo_points):\n",
    "                        elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "                        decistion_body,Ndecistion_body = \"Moving Body\",1   \n",
    "                    else:\n",
    "                        decistion_body,Ndecistion_body = \"Rest Body\",0\n",
    "                \n",
    "                LEFTangle , RIGHTangle = calculate_left_right_arm_angle(landmarks,mp_pose,X)\n",
    "                freeLEFT.append(LEFTangle)\n",
    "                freeRIGHT.append(RIGHTangle)\n",
    "                if len(freeLEFT)>1:\n",
    "                    l_is_moved = check_hand_moving(freeLEFT[-2],freeLEFT[-1])\n",
    "                else:\n",
    "                    l_is_moved = False\n",
    "                if len(freeRIGHT)>1:\n",
    "                    r_is_moved =check_hand_moving(freeRIGHT[-2],freeRIGHT[-1])\n",
    "                else:\n",
    "                    r_is_moved = False\n",
    "                \n",
    "                decistion_hand,Ndecistion_hand = hand_get_decistion(l_is_moved,r_is_moved)\n",
    "                \n",
    "                HFrameLable_kalman[key].append(Ndecistion_hand)\n",
    "                \n",
    "                MFrameLable_kalman[key].append(Ndecistion_body)\n",
    "                \n",
    "                ind.append(index)\n",
    "                \n",
    "                index+=1\n",
    "            except:\n",
    "                pass\n",
    "            cv2.putText(image,decistion_hand,(0,25),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "            cv2.putText(image,decistion_body,(0,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "#             decistion_hand=\"\"\n",
    "#             decistion_body=\"\"\n",
    "#             Drawing_utils(image,results,mp_pose)\n",
    "            cv2.imshow('Body Movement Taske',image)\n",
    "\n",
    "\n",
    "            if cv2.waitKey(10)==ord('q'):\n",
    "                break\n",
    "    indall.append(ind)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TEDxBITSPilaniDubai++ BODY MOV\n"
     ]
    }
   ],
   "source": [
    "path_folder = 'D:\\\\DataSet\\\\representatiion_scoring_data_set'\n",
    "folders ,videos = get_videos(path_folder)\n",
    "HFrameLable_kalman = {}\n",
    "MFrameLable_kalman = {}\n",
    "FrameLable_kalman = {}\n",
    "indall = []\n",
    "folders , all_video_paths = get_videos(path_folder)\n",
    "for i in all_video_paths[:1]:\n",
    "    try:\n",
    "        pipeline_with_kalman(i)\n",
    "    except:\n",
    "        pass\n",
    "for i in HFrameLable_kalman:\n",
    "    FrameLable_kalman[i] = [HFrameLable_kalman[i],MFrameLable_kalman[i]]\n",
    "# save_object(FrameLable_kalman,\"FrameLable_kalman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_object(HFrameLable_kalman,\"HFrameLable_kalman\")\n",
    "# save_object(MFrameLable_kalman,\"MFrameLable_kalman\")\n",
    "# save_object(indall,\"indall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_hypard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline_with_kalman(path_A):\n",
    "#     ind = []\n",
    "#     freeRIGHT = []\n",
    "#     freeLEFT = []\n",
    "#     temp = True\n",
    "#     head_points = []\n",
    "#     elbo_points = []\n",
    "#     decistion_hand = \"\"\n",
    "#     decistion_body = \"\"\n",
    "#     path_A_ = path_A.split(\"\\\\\")\n",
    "#     key = path_A_[-1].split(\".\")[-2].split(\"-\")[-1]+\" \"+path_A_[-2].split(\"-\")[-1]\n",
    "#     print(key)\n",
    "#     HFrameLable_kalman[key] = []\n",
    "#     MFrameLable_kalman[key] = []\n",
    "#     points_in_frames = []\n",
    "#     my_list = []\n",
    "#     index = 0 \n",
    "#     mp_pose = mp.solutions.pose \n",
    "#     cap = cv2.VideoCapture(path_A)\n",
    "#     if (cap.isOpened() == False): \n",
    "#         print(\"Error reading video file\")\n",
    "#     frame_width = int(cap.get(3))\n",
    "#     frame_height = int(cap.get(4))\n",
    "#     size = (frame_width, frame_height)\n",
    "#     frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     seconds = round(frames / fps)\n",
    "#     video_time = datetime.timedelta(seconds=seconds)\n",
    "#     delta_t = 1/fps\n",
    "#     A,P,H,R,Q,X = creat_kalman_parameters(delta_t)\n",
    "#     with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "#         while cap.isOpened():\n",
    "#             ret, frame = cap.read()\n",
    "#             if (not ret) or (cv2.waitKey(10)==ord('q')):\n",
    "#                 break\n",
    "#             image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "#             results = pose.process(image)\n",
    "#             image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "#             try:\n",
    "#                 landmarks = results.pose_landmarks.landmark\n",
    "#                 points_in_frames.append(landmarks)\n",
    "# #                 if index!=0:\n",
    "#                 my_list = calculate_distances(delta_t,points_in_frames[index],points_in_frames[index-1])\n",
    "#                 if index==1:\n",
    "#                     X = my_list\n",
    "#                 for i in range(len(my_list)):\n",
    "#                     Z = my_list[i]\n",
    "#                     X[i] , P = Prediction_update(X[i],A,P,Q)\n",
    "#                     X[i] , P , K = Measurement_update(Z,X[i],P,H,R)\n",
    "\n",
    "#                 NOSE = X[0][0][0]\n",
    "#                 LEFT_SHOULDER = X[1][0][0]\n",
    "#                 RIGHT_SHOULDER = X[2][0][0]\n",
    "#                 if NOSE and temp:\n",
    "#                     temp=False\n",
    "#                     head_points.append(NOSE)\n",
    "#                     elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "#                 if len(head_points)>=1:\n",
    "#                     head_points.append(NOSE)\n",
    "#                     elbo_points.append([LEFT_SHOULDER,RIGHT_SHOULDER])\n",
    "                    \n",
    "#                     if check_body_moving(index,head_points,elbo_points) :\n",
    "#                         decistion_body,Ndecistion_body = \"Moving Body\",1\n",
    "#                     else:\n",
    "#                         decistion_body,Ndecistion_body = \"Rest Body\",0\n",
    "                \n",
    "#                 LEFTangle , RIGHTangle = calculate_left_right_arm_angle(landmarks,mp_pose,X)\n",
    "#                 freeLEFT.append(LEFTangle)\n",
    "#                 freeRIGHT.append(RIGHTangle)\n",
    "#                 if len(freeLEFT)>1:\n",
    "#                     l_is_moved = check_hand_moving(freeLEFT[-2],freeLEFT[-1])\n",
    "#                 else:\n",
    "#                     l_is_moved = False\n",
    "#                 if len(freeRIGHT)>1:\n",
    "#                     r_is_moved =check_hand_moving(freeRIGHT[-2],freeRIGHT[-1])\n",
    "#                 else:\n",
    "#                     r_is_moved = False\n",
    "                \n",
    "#                 decistion_hand,Ndecistion_hand = hand_get_decistion(l_is_moved,r_is_moved)\n",
    "                \n",
    "#                 HFrameLable_kalman[key].append(Ndecistion_hand)\n",
    "                \n",
    "#                 MFrameLable_kalman[key].append(Ndecistion_body)\n",
    "                \n",
    "#                 ind.append(index)\n",
    "                \n",
    "#                 index+=1\n",
    "#             except:\n",
    "#                 pass\n",
    "# #             cv2.putText(image,decistion_hand,(0,25),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "# #             cv2.putText(image,decistion_body,(0,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "# #             decistion_hand=\"\"\n",
    "# #             decistion_body=\"\"\n",
    "# #             Drawing_utils(image,results,mp_pose)\n",
    "# #             cv2.imshow('Body Movement Taske',image)\n",
    "\n",
    "\n",
    "#             if cv2.waitKey(10)==ord('q'):\n",
    "#                 break\n",
    "#     indall.append(ind)\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_folder = 'D:\\\\DataSet\\\\representatiion_scoring_data_set'\n",
    "# folders ,videos = get_videos(path_folder)\n",
    "# HFrameLable = {}\n",
    "# MFrameLable = {}\n",
    "# FrameLable = {}\n",
    "# indall = []\n",
    "# folders , all_video_paths = get_videos(path_folder)\n",
    "# for i in [all_video_paths[0],all_video_paths[14]]:\n",
    "#     try:\n",
    "#         pipeline(i)\n",
    "#     except:\n",
    "#         pass\n",
    "# for i in HFrameLable:\n",
    "#     FrameLable[i] = [HFrameLable[i],MFrameLable[i]]\n",
    "# # save_object(FrameLable,\"FrameLable++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "#     \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "#     columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "#     empty_cell = \" \" * columnwidth\n",
    "#     # Print header\n",
    "#     print(\"    \" + empty_cell, end=\" \")\n",
    "#     for label in labels:\n",
    "#         print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "#     print()\n",
    "#     # Print rows\n",
    "#     for i, label1 in enumerate(labels):\n",
    "#         print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "#         for j in range(len(labels)):\n",
    "#             cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "#             if hide_zeroes:\n",
    "#                 cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "#             if hide_diagonal:\n",
    "#                 cell = cell if i != j else empty_cell\n",
    "#             if hide_threshold:\n",
    "#                 cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "#             print(cell, end=\" \")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_test , y_predicted = np.array(y_test) , np.array(y_predicted)\n",
    "\n",
    "\n",
    "# confusion = confusion_matrix(y_test, y_predicted) # y_test, y_pridicte is numpy array\n",
    "\n",
    "# print_cm(confusion, ['Zero', 'One'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predicted))) # y_test, y_pridicte is numpy array\n",
    "# print('Precision: {:.2f}'.format(precision_score(y_test, y_predicted))) # y_test, y_pridicte is numpy array\n",
    "# print('Recall: {:.2f}'.format(recall_score(y_test, y_predicted))) # y_test, y_pridicte is numpy array\n",
    "# print('F1: {:.2f}'.format(f1_score(y_test, y_predicted))) # y_test, y_pridicte is numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combined report with all above metrics\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# print(classification_report(y_test, tree_predicted, target_names=[' 0 ', ' 1 ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
